---
layout: speaker
name: Dinesh Jayaraman
role: Assistant Professor
institution: University of Pennsylvania
date: Feb 26th, 2025
label: Feb 26th, 2025
time: "2:00 pm - 3:00 pm EST"
day: day2
website: "https://www.seas.upenn.edu/~dineshj/"
image: "/dc2025/images/dinesh.jpg"
title: "Engineering Better Robot Learners: Exploitation &amp; Exploration"
abstract: "Industry is placing big bets on &quot;brute forcing&quot; robotic control, but such approaches are profligate in their use of expensive resources in robotics: power, compute, time, data, etc. Good engineering principles would hold that we should aim to develop more minimalist robotic control stacks, which requires understanding the tradeoffs between task performance and resource usage. My research group has been &quot;exploiting and exploring&quot; robot learning: exploiting to push the limits of what can be achieved with today&rsquo;s prevalent principles, and &quot;exploring&quot; by asking foundational questions towards building better design principles for efficient and minimalist robots in the future. As examples of &quot;exploit&quot;, we have trained quadruped robots to perform circus tricks on yoga balls and robot arms to perform household tasks in entirely unseen scenes with unseen objects. As examples of &quot;explore&quot;, we are studying the sensory requirements of robot learners: what sensors do they need and when during training and task execution do they need them? In this talk, I will highlight these examples, and discuss some lessons we have learned in our research towards better-engineered robot learners. "
bio: "Dinesh Jayaraman is an assistant professor in the University of Pennsylvania&rsquo;s CIS department. Before this, he was a visiting research scientist at Facebook AI Research, Menlo Park and was a postdoctoral scholar at UC Berkeley. He received his PhD from UT Austin (2017), and his Bachelor&rsquo;s degree from IIT Madras (2011).  Dinesh&rsquo;s research focuses on questions at the intersections of perception, learning, and robotic control, such as: how might perception (such as from high-resolution optical / tactile sensors) benefit from the ability to act in the world, and vice versa? And how can effective visual control algorithms that exploit these perception-action cycles help in bringing general purpose affordable robots into our homes and workplaces? Towards answering these questions, he studies a broad range of topics, from predictive models for model-based RL and planning, to self-supervised visual representation learning, active perception, visuo-tactile robotic manipulation, causal inference, visual servoing, semantic visual attributes, and zero-shot categorization."
---
